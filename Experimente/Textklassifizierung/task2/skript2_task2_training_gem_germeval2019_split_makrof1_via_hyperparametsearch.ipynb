{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uPMxhsCGC_28"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "T03dQvvEfKLV"
   },
   "outputs": [],
   "source": [
    "#!pip install seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcT7J9elDafr"
   },
   "source": [
    "# Skript2: Model Finetuning mit Hyperparametersuche für Text-Klassifizierung mit germaneval2019 Task2 -Subtask2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Notebook beschreibt das Training eines Text-Klassifizierungsmodells für den Datensatz GermEval 2019 Task2 -Subtask2.\n",
    "Es wird ein BERT - Modell mit der nativen Hugging Face Transformer Bibliothek trainiert. Dafür wird vor dem Training mithilfe automatischer Hyperparametersuche versucht, bessere Trainingsparameter zu finden, um die Modellleistung zu verbessern. Das Training erfolgt nach dem gleichen Split wie es der Shared Task 2019 vorgab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IMjJp0dTDQYd"
   },
   "outputs": [],
   "source": [
    "# Importieren der Hugging Face Datesets Bibliothek\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w1-KB44DGj0Y"
   },
   "outputs": [],
   "source": [
    "# Parameter für die Scriptsteuerung:\n",
    "# die Task für die das Modell trainiert werden soll\n",
    "task = \"task2\"\n",
    "# das zu verwendende pretrained Transformer Modell\n",
    "model_checkpoint = \"deepset/gbert-base\"\n",
    "# die Trainingsbatchsize\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCubx_AkH_9c"
   },
   "source": [
    "## Preprocessing des Datasets\n",
    "Zunächst müssen die Daten aus dem GermEval2019 Datensatz vorverarbeitet werden. Dazu werden diese in einen `Pandas DataFrames` umgewandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HvPtCFtYMl1c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9wMKF4EWZZo"
   },
   "source": [
    "Als ersten werden mit Hilfe der `read_csv()` Methode die Daten für das Trainings- und das Valiederungsset zu einem `DataFrame` zusammengefügt. Dabei werden die Werte in den Labelspalten in numerische Kategorienencodings umgewandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 6801,
     "status": "ok",
     "timestamp": 1611008225006,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "_EA1WWnEMr-S",
    "outputId": "5a9b7b63-7cce-45d2-b104-ce0deec446b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task1_label</th>\n",
       "      <th>task2_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meine Mutter hat mir erzählt, dass mein Vater ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Tom174_ @davidbest95 Meine Reaktion; |LBR| Ni...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Merkel rollt dem Emir von #Katar, der islamis...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>„Merle ist kein junges unschuldiges Mädchen“ K...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@umweltundaktiv Asylantenflut bringt eben nur ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>250 Menschen auf der Demonstration gegen das D...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>Erneut Massaker an Kurdische ZivilistInnen dur...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>Hunderte Refugees haben die Grenze zur spanisc...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>Heute ab 17:00 Uhr an der Alten Oper FFM: Kund...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>Uns gibt es jetzt auch auf #twitter. Folgt uns...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12536 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  task1_label  \\\n",
       "0     Meine Mutter hat mir erzählt, dass mein Vater ...            1   \n",
       "1     @Tom174_ @davidbest95 Meine Reaktion; |LBR| Ni...            1   \n",
       "2     #Merkel rollt dem Emir von #Katar, der islamis...            1   \n",
       "3     „Merle ist kein junges unschuldiges Mädchen“ K...            1   \n",
       "4     @umweltundaktiv Asylantenflut bringt eben nur ...            0   \n",
       "...                                                 ...          ...   \n",
       "3990  250 Menschen auf der Demonstration gegen das D...            1   \n",
       "3991  Erneut Massaker an Kurdische ZivilistInnen dur...            1   \n",
       "3992  Hunderte Refugees haben die Grenze zur spanisc...            1   \n",
       "3993  Heute ab 17:00 Uhr an der Alten Oper FFM: Kund...            1   \n",
       "3994  Uns gibt es jetzt auch auf #twitter. Folgt uns...            1   \n",
       "\n",
       "      task2_label  \n",
       "0               2  \n",
       "1               2  \n",
       "2               2  \n",
       "3               2  \n",
       "4               0  \n",
       "...           ...  \n",
       "3990            2  \n",
       "3991            2  \n",
       "3992            2  \n",
       "3993            2  \n",
       "3994            2  \n",
       "\n",
       "[12536 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=pd.read_csv(\"../datasets/germeval2019/train_valid/germeval2018.test_.txt\",delimiter=\"\\t\", header=None,quoting=3)\n",
    "data2=pd.read_csv(\"../datasets/germeval2019/train_valid/germeval2018.training.txt\",delimiter=\"\\t\", header=None,quoting=3)\n",
    "data3=pd.read_csv(\"../datasets/germeval2019/train_valid/germeval2019.training_subtask1_2_korrigiert.txt\",delimiter=\"\\t\", header=None,quoting=3)\n",
    "data_all = data1.append([data2,data3])\n",
    "data_all.columns = [\"text\",\"task1_label\",\"task2_label\"]\n",
    "# Umwandlung der Label in die jeweiligen numerischen Encodings\n",
    "data_all.task1_label = data_all.task1_label.astype('category').cat.codes\n",
    "data_all.task2_label = data_all.task2_label.astype('category').cat.codes\n",
    "data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das Testdataset wird ebenfalls ein `DataFrame` erzeugt und die Label encodiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task1_label</th>\n",
       "      <th>task2_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@JanZimmHHB @mopo Komisch das die Realitätsver...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@faznet @Gruene_Europa @SPDEuropa @CDU CDU ste...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DLFNachrichten Die Gesichter, Namen, Religion...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@welt Wie verwirrt muss man sein um sich zu we...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@hacker_1991 @torben_braga Weil die AfD den Fe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3026</th>\n",
       "      <td>Es fand aber nie eine Emanzipierungs-Phase der...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3027</th>\n",
       "      <td>Um es klar zu stellen: Ich will hier kein Whit...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3028</th>\n",
       "      <td>Und dann habe ich da noch die McArthur-Briefe ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029</th>\n",
       "      <td>al sehen wer der Ersatzmann wird. Hier könnte ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030</th>\n",
       "      <td>@JKasek Oder die Bäume. Bin mal in 'nem Wald s...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3031 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  task1_label  \\\n",
       "0     @JanZimmHHB @mopo Komisch das die Realitätsver...            0   \n",
       "1     @faznet @Gruene_Europa @SPDEuropa @CDU CDU ste...            0   \n",
       "2     @DLFNachrichten Die Gesichter, Namen, Religion...            1   \n",
       "3     @welt Wie verwirrt muss man sein um sich zu we...            0   \n",
       "4     @hacker_1991 @torben_braga Weil die AfD den Fe...            0   \n",
       "...                                                 ...          ...   \n",
       "3026  Es fand aber nie eine Emanzipierungs-Phase der...            1   \n",
       "3027  Um es klar zu stellen: Ich will hier kein Whit...            1   \n",
       "3028  Und dann habe ich da noch die McArthur-Briefe ...            1   \n",
       "3029  al sehen wer der Ersatzmann wird. Hier könnte ...            1   \n",
       "3030  @JKasek Oder die Bäume. Bin mal in 'nem Wald s...            1   \n",
       "\n",
       "      task2_label  \n",
       "0               1  \n",
       "1               0  \n",
       "2               2  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "3026            2  \n",
       "3027            2  \n",
       "3028            2  \n",
       "3029            2  \n",
       "3030            2  \n",
       "\n",
       "[3031 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"../datasets/germeval2019/test/germeval2019GoldLabelsSubtask1_2.txt\",delimiter=\"\\t\", header=None, quoting=3)\n",
    "data_test.columns = [\"text\",\"task1_label\",\"task2_label\"]\n",
    "data_test.task1_label = data_test.task1_label.astype('category').cat.codes\n",
    "data_test.task2_label = data_test.task2_label.astype('category').cat.codes\n",
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPgChng8W-2R"
   },
   "source": [
    "Anschließend kann aus den `Pandas DataFrames` ein `Hugging Face Dataset` generiert werden. Hierfür wird zunächst ein `Feature` Dictionary erzeugt. Dieses enthält Typisierungen für die Features des Datasets. So werden die Features `task1_label` und `task2_label` jeweils als `ClassLabel` typisiert und das `text` Feature wird als String-Value deklariert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OasUiOPHRlcX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Erzeugen eines DataSet Objektes mit allen Daten\n",
    "features = datasets.Features({\n",
    "  #'__index_level_0__': datasets.Value(dtype='int32', id=None),\n",
    "  'task1_label': datasets.ClassLabel(num_classes=2, names=['OFFENSE', 'OTHER'], names_file=None, id=None),\n",
    "  'task2_label': datasets.ClassLabel(num_classes=4, names=['ABUSE', 'INSULT', 'OTHER', 'PROFANITY'], names_file=None, id=None),\n",
    "  'text': datasets.Value(dtype='string', id=None)\n",
    "})\n",
    "dataset = datasets.Dataset.from_pandas(data_all,features=features)\n",
    "dataset_test = datasets.Dataset.from_pandas(data_test,features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beispielausgabe der Dataset Objekte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['task1_label', 'task2_label', 'text'],\n",
       "     num_rows: 3031\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['task1_label', 'task2_label', 'text'],\n",
       "     num_rows: 12536\n",
       " }))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-tOmELjZNGD"
   },
   "source": [
    "#### Split des Datasets\n",
    "Mithilfe der der Dataset Objekte wird anschließend der Trainings- und Validierungssplit durchgeführt. Die gewählte größe des Validierungsset beträgt 20% des Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EiGTIJWUTnlI"
   },
   "outputs": [],
   "source": [
    "# Aufsplitten des Trainingssets in 80/20 (Training/Validation)Split\n",
    "dataset_train_valid = dataset.train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `train_test_split()` Methode gibt ein `DatasetDict` Objekt zurück. Dies ist ein Dictionary mit einem Trainings- und einem Testdataset. Das Testdataset stellt in diesem Fall das Validierungsdataset dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['task1_label', 'task2_label', 'text'],\n",
       "        num_rows: 10028\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['task1_label', 'task2_label', 'text'],\n",
       "        num_rows: 2508\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein gemeinsames Dataset Objekt zu erhalten, werden die Datasets anschließend zusammengefügt und entsprechend des Splits benannt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Jjr8Dp7Fadpp"
   },
   "outputs": [],
   "source": [
    "# Zusammenfügen aller DataSet-Objekte zu einem gemeinsamen DataSet mit benannten Splits\n",
    "dataset_train_valid_test = datasets.DatasetDict({\"train\": dataset_train_valid[\"train\"],\n",
    "                                                 \"valid\": dataset_train_valid[\"test\"],\n",
    "                                                 \"test\": dataset_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufbau des gesamten Dataset Dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7293,
     "status": "ok",
     "timestamp": 1611008225519,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "_8UgCr4ERdSl",
    "outputId": "f7fba697-a7c5-4f5d-c690-609b9b80928a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['task1_label', 'task2_label', 'text'],\n",
       "        num_rows: 10028\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['task1_label', 'task2_label', 'text'],\n",
       "        num_rows: 2508\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['task1_label', 'task2_label', 'text'],\n",
       "        num_rows: 3031\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_valid_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTA7nlywIniv"
   },
   "source": [
    "Funktion für die Ausgabe von Beispieldaten aus dem Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uEnpzJT7Iegv"
   },
   "outputs": [],
   "source": [
    "# Quelle in Anlehnung an: https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/text_classification.ipynb#scrollTo=X6HrpprwIrIz\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10,seed=None):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    random.seed(seed)\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            random.seed(seed)\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausgabe von Beispieldaten aus dem Trainingsdataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 8263,
     "status": "ok",
     "timestamp": 1611008226504,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "vRus2k0ZIqyJ",
    "outputId": "ff95e91c-38a2-4a6c-981d-9a3dd410b55d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task1_label</th>\n",
       "      <th>task2_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>@AfDimBundestag @Heinrich_Krug Gehört den zu einer Integration nicht auch die Bräuche des jeweiligen zu akzeptieren..? |LBR| Und wer das nicht tut welchen Sinn gibt es noch denjenigen unter uns zu wissen..? |LBR| Ich bin für Weihnachtsbäume statt Moscheen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>immerhin entstehen auch neue räume für die StArTuP sZEnE *-*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OFFENSE</td>\n",
       "      <td>INSULT</td>\n",
       "      <td>@FOJ45360104 @Papier451 Bei einigen Promis zeigt sich das sie entweder zu viele Schnaps Pralinen gefuttert haben oder was wahrscheinlicher ist eine Gehirn Prothese tragen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OFFENSE</td>\n",
       "      <td>ABUSE</td>\n",
       "      <td>Das lustige am Feminismus ist ja, dass dieser alle negativen Klischees über Frauen bestätigt ☺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>@mountainman1977 @StapelChipsYT Au ja. Ich stell Dir Dein Zeugnis aus :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OFFENSE</td>\n",
       "      <td>INSULT</td>\n",
       "      <td>Diese Göring ist die schlimmste Lügen-Erzählerin Deutschlands. Schlimm das DIE in die Regierung kommt. #illner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Martin Schulz ist Kanzlerkandidat der SPD ohne Schulabschluss. Er ist |LBR| 2 x sitzen geblieben. Ist das Ihre Führungsspitze?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OFFENSE</td>\n",
       "      <td>ABUSE</td>\n",
       "      <td>@prussian_pride Er ist nur noch ein Mettwoch vom Herzkasper entfernt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OFFENSE</td>\n",
       "      <td>ABUSE</td>\n",
       "      <td>Freiheit und Vielfalt sind immer dann gewährleistet, wenn alle Frau_innen Kopftuch tragen und jeder dieselbe linke Meinung hat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>@SPDJevenstedt @WilmsVal @Ralf_Stegner 10 Minuten spricht jemand #ProGoKo. 10 Minuten spricht jemand #NoGroKo. Reihefolge wird ausgelost. Und dann dürfen sich alle zu Wort melden. @Ralf_Stegner oder die Redner.innen antworten dann auf Fragen nach 4-5 Wortmeldungen.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset_train_valid_test[\"train\"],seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKOyNmu29mJh"
   },
   "source": [
    "# Preprocessing der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9n5Si_z-GPZ"
   },
   "source": [
    "Beschaffen des zugehörigen Tokenizers zum ausgewählten Modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hdtek_WJ21iW"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Tokenizer kann direkt genutzt werden, um eine Inputsequenz zu tokenisieren. Dabei erhält man ein Dictionary mit Mappings zu den input_ids, token_type_ids und eine attention_mask. Die input_id ist die Identifikation des jeweiligen Tokens im Vokabluar des Modells. Token_type_ids markieren Tokens in Seq2Seq Tasks und geben dem Modell Informationen darüber, zu welchem Teil einer zweiteiligen Eingabesequenz ein Token gehört. Die attention_mask teilt dem Modell mit, für welche Token die Attention berechnet werden soll. Ist eine Eingabesequenz z. B. sehr kurz im Gegensatz zu den anderen, dann wird diese per Padding auf die gleiche Länge gebracht. Die attention_mask verhindert anschließend, dass die Attention für diese Padding Token berechnet wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12322,
     "status": "ok",
     "timestamp": 1611008230579,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "eX3dokKC-EBJ",
    "outputId": "adf21783-9a9a-4cc2-e5b1-6fa9b1be7691"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [102, 479, 215, 3392, 827, 12822, 313, 3750, 2809, 8550, 205, 11473, 11545, 7232, 276, 190, 8448, 106, 128, 21429, 205, 3915, 566, 2302, 1523, 28283, 105, 818, 276, 128, 2233, 5099, 205, 21713, 11044, 566, 103], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Es ist natürlich viel einfacher auch weiterhin jeden Widerstand zu skandalisieren als den Konzernen die Stirn zu bieten. Ist einfach gemütlicher, als die eigenen Fehler zu reflektieren.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Daten der Datasets vorzuverarbeiten wird die folgende Methode definiert\\\n",
    "In der Methode werden zunächst die Werte des `text` Features mit dem Tokenizer des Modells tokeniesiert und anschließend ein Label Attribut mit dem Wert der aktuellen Task eingefügt. Die Methode gibt Ausgabe des Tokenizers anschließend zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2GnFhohw-d-1"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "  tokenized_inputs = tokenizer(data['text'], truncation=True)\n",
    "  if task.endswith(\"1\"):\n",
    "    label = data[\"task1_label\"]\n",
    "  else:\n",
    "    label = data[\"task2_label\"]\n",
    "  tokenized_inputs[\"label\"] = label\n",
    "  return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6QhEXZt_41k"
   },
   "source": [
    "Die Funktion kann beliebig viele Datensätze verarbeiten. Werden mehrere übergeben dann gibt der Tokenizer eine Liste zurück:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12311,
     "status": "ok",
     "timestamp": 1611008230580,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "ivcqbxsL_ZBP",
    "outputId": "6538c988-af1a-455a-ac6f-0e4915218f07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[102, 17329, 3505, 2354, 17338, 105, 5561, 17329, 2812, 1662, 3225, 2641, 700, 262, 1743, 319, 1571, 335, 840, 5421, 1110, 778, 1421, 2361, 255, 268, 4604, 7971, 2856, 128, 10037, 153, 125, 23699, 450, 8433, 341, 128, 816, 22398, 3460, 103]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'label': [1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_data(dataset_train_valid_test[\"train\"][:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0FGhYm_AR9U"
   },
   "source": [
    "Anwendung der `preprocess_data` Funktion auf alle Teildatensätze im DataSet-Objekt `dataset_train_valid_test` mithilfe von `map`\n",
    " - `batched=True` beschleunigt die Verarbeitung des FastTokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167,
     "referenced_widgets": [
      "1d0b4221fcd5470687de22c0d2adcb95",
      "65f7cf127c6a44a9a4c5a457670cfa3a",
      "15be95196266497ab2fbab5e11853161",
      "4d41e7ef93c646ed88b99644e47247c4",
      "dff609ca3a5248cd8de78e1ba12b3dba",
      "6db3d3a6df294530a9756b3873ff6d7a",
      "baae8d84bcb24170a7c4ff7f6c7a45bc",
      "711f7d49b8aa44b886cf8421cf650877",
      "99afef5741a248118be99ba48f82e3d9",
      "0d6f7447273c49bcbe6557770812e45a",
      "1b376abbf52347cea599ecbd8a200f9b",
      "a2ce89d47bd944e2936859b9d6880d03",
      "8196b689e3df44fe93eb6de3ce2d398a",
      "d87d7aaa52c94a7cbc2b0145601ff16a",
      "e376402eed794262ac376ba1bae6e551",
      "48946d29567b4ca79e74c1519ce4e98b",
      "7477eb3df24a4233b83a8b2a40860597",
      "86ff3ad9403d43af94b11942cb0952f9",
      "e7176033658a4bad8c12d76e86afb0d6",
      "ab5198481b23416c9308d2b1088daf62",
      "f200ec38e21a4fa0a177c1c09e7f6342",
      "63b3a67d23b04628bd266546814febff",
      "f5dcd7aa0ae2476db993b3ee5de33c0f",
      "fcbdcd3f6b4b4d329831b0da8d3c105f"
     ]
    },
    "executionInfo": {
     "elapsed": 14410,
     "status": "ok",
     "timestamp": 1611008232685,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "twrsVzjj_mR8",
    "outputId": "4876bb83-6d0f-4794-d152-9c88cfee069a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bf6b2422494e479b03041681ac470b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd9c22c55864c64b848f1bcdafe84de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125e2813d42d4357bbced8238fb518cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_preprocessed = dataset_train_valid_test.map(preprocess_data,batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gb_TD4XlBWVb"
   },
   "source": [
    "Durch das Preprocessing werden die Ausgaben des Tokenizers als Features des DataSets ergänzt.\\\n",
    "In der folgenden Ausgaben sieht man, dass nun die attention_mask, die input_ids, die label und die token_type_ids als Features ergänzt wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14404,
     "status": "ok",
     "timestamp": 1611008232686,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "06uMbiXMA6cy",
    "outputId": "b7331279-1f55-4304-b6ae-ec8e72fb2fec",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'label', 'task1_label', 'task2_label', 'text', 'token_type_ids'],\n",
       "    num_rows: 10028\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_preprocessed[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>label</th>\n",
       "      <th>task1_label</th>\n",
       "      <th>task2_label</th>\n",
       "      <th>text</th>\n",
       "      <th>token_type_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[102, 17329, 7561, 328, 28742, 246, 17329, 4669, 2032, 20611, 30894, 22098, 30885, 190, 205, 369, 7106, 255, 313, 128, 24546, 2041, 222, 5288, 205, 14499, 566, 566, 1992, 18406, 183, 14822, 18406, 700, 309, 199, 255, 4273, 9817, 6112, 800, 288, 447, 23374, 389, 734, 205, 1770, 566, 566, 1992, 18406, 183, 14822, 18406, 395, 1089, 231, 5834, 21712, 1477, 25534, 30882, 103]</td>\n",
       "      <td>2</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>@AfDimBundestag @Heinrich_Krug Gehört den zu einer Integration nicht auch die Bräuche des jeweiligen zu akzeptieren..? |LBR| Und wer das nicht tut welchen Sinn gibt es noch denjenigen unter uns zu wissen..? |LBR| Ich bin für Weihnachtsbäume statt Moscheen</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[102, 13795, 5677, 313, 1133, 10201, 30881, 231, 128, 234, 3120, 30923, 30890, 30920, 117, 24626, 30882, 30913, 1178, 232, 1178, 103]</td>\n",
       "      <td>2</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>immerhin entstehen auch neue räume für die StArTuP sZEnE *-*</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset_preprocessed[\"train\"],seed=42,num_examples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzkAGoLuCEOT"
   },
   "source": [
    "# Finetuning des Modells mit Hyperparametersearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kx9YcmiEGs4V"
   },
   "source": [
    "Für die Konstruktion des Modells wird ein Label-ID Mapping erzeugt. Dieses Mapping wird anschließend in der Configuration des Modells hinterlegt. Es ermöglicht dem Modell die vorhergesagten Label als Texte auszugeben anstatt ihrer numerischen Kodierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AC8I1QPTFIv9"
   },
   "outputs": [],
   "source": [
    "if task.endswith(\"1\"):\n",
    "  id2label = {\"0\":\"OFFENSE\", \"1\":\"OTHER\"}\n",
    "  label2id = {\"OFFENSE\": \"0\", \"OTHER\":\"1\"}\n",
    "else:\n",
    "  id2label = {\"0\":\"ABUSE\", \"1\":\"INSULT\",\"2\": \"OTHER\", \"3\": \"PROFANITY\"}\n",
    "  label2id = {\"ABUSE\": \"0\", \"INSULT\":\"1\", \"OTHER\": \"2\", \"PROFANITY\": \"3\"}\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqUjcxMAGyCe"
   },
   "source": [
    "Erzeugen und Konfiguration des Modells mit Label-ID Mapping:\n",
    " - `AutoModelForSequenceClassification.from_pretrained` lädt automatisch das entsprechende Modell herunter und initialisiert einen Klassifizierungskopf am Ende des Modells.\n",
    " - Die auftretenden Warnungen geben nur Auskunft darüber, dass der Kopf des Modells ausgetauscht wurde und demzufolge keine trainierten Weights hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Annahme, dass bessere gewählte Hyperparameter leistungsstärkeren Modellen führen, wird im folgenden Abschnitt mithilfe von automatischer Hyperparametersuche versucht, die Modellperformance weiter zu steigern. \\\n",
    "Hierfür wird das Modul optuna genutzt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es muss eine Funktion erstellt werden, die das zu trainierende Modell nach jedem Versuch wieder initalisiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "num_labels = 2 if task.endswith(\"1\") else 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisiert ein neues Modell auf Basis des gewählten Modell Checkpoints\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuRkOYLmJKc8"
   },
   "source": [
    "#### Vorbereitung für die Erzeugung des `Trainers`:\n",
    "- Es müssen zunächst die `TrainingArguments` konfiguriert werden, dabei handelt es sich um die Hyperparameter des Trainings:\n",
    " - Dazu zählen z.B. die Anzahl der Epoch, die Learning Rate, die Batchsize und der weight_decay\n",
    " - `load_best_model_at_end` und `metric_for_best_model` sorgen dafür, dass am Ende des Trainings das Model mit der höchsten `F1_Score` geladen wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "gyKgE9MXCyUM"
   },
   "outputs": [],
   "source": [
    "metric_name = 'eval_f1'\n",
    "\n",
    "args = TrainingArguments( \n",
    "    output_dir= f\"{task}_transformer_hyperparametersearch\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    # empfohlener Standardwert für das Finetuning\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    # empfohlener Standardwert für das Finetuning\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    # fp16 transformiert das Modell nach float16 um Memory zu sparen und die Trainingszeit zu verringern\n",
    "    fp16=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLTFfL73KtsO"
   },
   "source": [
    "Damit das Modell während des Trainings die gewünschten Metriken berechnen kann, muss eine Funktion definiert werden die diese Metriken berechnet. Das übernimmt die `compute_metric` Funktion:\n",
    "- Die Datasets Bibliothek ermöglicht es, Funktionen zur Berechnung von Metriken herunterzuladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "rm6IRaplamcX"
   },
   "outputs": [],
   "source": [
    "metric_acc = datasets.load_metric(\"accuracy\")\n",
    "metric_f1 = datasets.load_metric(\"f1\")\n",
    "metric_prec = datasets.load_metric(\"precision\")\n",
    "metric_rec = datasets.load_metric(\"recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Metriken werden nun wie folgt in der `compute_metrics` Funktion berechnet. Die Funktion liefert anschließend ein Dictionary mit den vier Metriken `accuracy, precision, recall, f1` zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "-dwIvncrKzGx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(p):\n",
    "  predictions, labels = p\n",
    "  predictions = np.argmax(predictions, axis=1)\n",
    "  accurracy = metric_acc.compute(predictions=predictions, references=labels)\n",
    "  f1 = metric_f1.compute(predictions=predictions, references=labels, average=\"macro\" )\n",
    "  prec = metric_prec.compute(predictions=predictions, references=labels,average=\"macro\")\n",
    "  recall = metric_rec.compute(predictions=predictions, references=labels,average=\"macro\")\n",
    " \n",
    "  return {\n",
    "      \"accurracy\" : accurracy[\"accuracy\"],\n",
    "      \"precision\" : prec[\"precision\"],\n",
    "      \"recall\": recall[\"recall\"],\n",
    "      \"f1\": f1[\"f1\"]\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T99e_CdMMl5G"
   },
   "source": [
    "Anschließend muss ein Trainer initialisiert werden, welcher für die Hyperparametersuche genutzt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "j923iZq8LsZs",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer_hyper = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=dataset_preprocessed[\"train\"].shard(index=1, num_shards=10),\n",
    "    eval_dataset=dataset_preprocessed[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Festlegen der Hyperparameter die getestet werden sollen:\n",
    "- In diesem Beispiel werden Werte für die Learning Rate und die Anzahl der Epochs ermittelt. \n",
    "- Die Batchsize wurde auf 4 gesetzt um Out of Memoryprobleme zu vermeiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-2, log=True),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 1, 5),\n",
    "        #Festlegen er maximalen Batchsize um Cuda out of Memory zu vermeiden\n",
    "        \"per_device_train_batch_size\": trial.suggest_int(\"per_device_train_batch_size\", 4,4),\n",
    "        \"per_device_eval_batch_size\": trial.suggest_int(\"per_device_eval_batch_size\",4,4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Hyperparametersuche muss festgelegt werden, wie ein Durchlauf bewertetet werden soll.\n",
    "Hierfür werden mit der folgenden Funktion alle vom Modell berechneten Metriken aufsummiert. Die Summe ist der Score für die Epoch des jeweiligen Versuchs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def my_objective(metrics) -> float:\n",
    "    metrics = copy.deepcopy(metrics)\n",
    "    loss = metrics.pop(\"eval_loss\", None)\n",
    "    _ = metrics.pop(\"epoch\", None)\n",
    "    _ = metrics.pop(\"eval_runtime\",None)\n",
    "    _ = metrics.pop(\"eval_samples_per_second\",None)\n",
    "    return loss if len(metrics) == 0 else sum(metrics.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starten der Hyperparametersuche:\n",
    "- es werden 10 Versuche durchgeführt\n",
    "- `direction=\"maximize\"` sorgt dafür, dass das beste Modell anhand der Maximalen Punktzahl der Evaluationsmetriken ausgewählt wird\n",
    "- die Methode returned als Ergebnis die verwendeten Hyperparameter des besten Versuchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-09 16:56:27,050]\u001b[0m A new study created in memory with name: no-name-0f5b947d-f933-4c2d-b5f8-ef99795f317f\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='753' max='753' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [753/753 01:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.733132</td>\n",
       "      <td>0.728868</td>\n",
       "      <td>0.501110</td>\n",
       "      <td>0.338112</td>\n",
       "      <td>0.347869</td>\n",
       "      <td>9.883100</td>\n",
       "      <td>253.768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.775200</td>\n",
       "      <td>0.780960</td>\n",
       "      <td>0.741228</td>\n",
       "      <td>0.452531</td>\n",
       "      <td>0.409569</td>\n",
       "      <td>0.421774</td>\n",
       "      <td>9.868800</td>\n",
       "      <td>254.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.775200</td>\n",
       "      <td>0.893374</td>\n",
       "      <td>0.734051</td>\n",
       "      <td>0.519091</td>\n",
       "      <td>0.392522</td>\n",
       "      <td>0.399886</td>\n",
       "      <td>9.993600</td>\n",
       "      <td>250.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-09 16:58:27,787]\u001b[0m Trial 0 finished with value: 2.045549773586954 and parameters: {'learning_rate': 1.5262149309394706e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4}. Best is trial 0 with value: 2.045549773586954.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1004' max='1004' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1004/1004 02:36, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.916750</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>9.979500</td>\n",
       "      <td>251.315000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.989400</td>\n",
       "      <td>0.895082</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>9.978400</td>\n",
       "      <td>251.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.989400</td>\n",
       "      <td>0.879602</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>10.229800</td>\n",
       "      <td>245.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.875100</td>\n",
       "      <td>0.875850</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>10.174300</td>\n",
       "      <td>246.504000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-09 17:01:08,016]\u001b[0m Trial 1 finished with value: 1.302130571206083 and parameters: {'learning_rate': 1.239083022990944e-06, 'num_train_epochs': 4, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4}. Best is trial 0 with value: 2.045549773586954.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1004' max='1004' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1004/1004 02:33, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.055230</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>9.907200</td>\n",
       "      <td>253.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.105500</td>\n",
       "      <td>1.014285</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>9.587900</td>\n",
       "      <td>261.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.105500</td>\n",
       "      <td>0.943207</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>9.780500</td>\n",
       "      <td>256.428000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.008700</td>\n",
       "      <td>0.918096</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>9.635400</td>\n",
       "      <td>260.291000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-09 17:03:46,178]\u001b[0m Trial 2 finished with value: 1.302130571206083 and parameters: {'learning_rate': 0.0014515802394745243, 'num_train_epochs': 4, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4}. Best is trial 0 with value: 2.045549773586954.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='251' max='251' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [251/251 00:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.857929</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>9.356400</td>\n",
       "      <td>268.052000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-09 17:04:30,425]\u001b[0m Trial 3 finished with value: 1.302130571206083 and parameters: {'learning_rate': 6.195537552560774e-06, 'num_train_epochs': 1, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4}. Best is trial 0 with value: 2.045549773586954.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='502' max='502' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [502/502 01:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.952854</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>9.355600</td>\n",
       "      <td>268.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.117700</td>\n",
       "      <td>0.921374</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>9.435200</td>\n",
       "      <td>265.812000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-09 17:05:50,910]\u001b[0m Trial 4 finished with value: 1.302130571206083 and parameters: {'learning_rate': 0.0017627591413978847, 'num_train_epochs': 2, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4}. Best is trial 0 with value: 2.045549773586954.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='252' max='753' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [251/753 00:24 < 00:48, 10.30 it/s, Epoch 1.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.425356</td>\n",
       "      <td>0.173445</td>\n",
       "      <td>0.043361</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.073904</td>\n",
       "      <td>9.545900</td>\n",
       "      <td>262.731000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-09 17:06:29,164]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='502' max='502' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [502/502 01:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.928929</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>9.513300</td>\n",
       "      <td>263.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.072600</td>\n",
       "      <td>0.916405</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>9.522200</td>\n",
       "      <td>263.384000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-09 17:07:48,953]\u001b[0m Trial 6 finished with value: 1.302130571206083 and parameters: {'learning_rate': 0.0014361599229760504, 'num_train_epochs': 2, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4}. Best is trial 0 with value: 2.045549773586954.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='502' max='502' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [502/502 01:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.713065</td>\n",
       "      <td>0.733652</td>\n",
       "      <td>0.483658</td>\n",
       "      <td>0.355283</td>\n",
       "      <td>0.362371</td>\n",
       "      <td>9.518200</td>\n",
       "      <td>263.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.760100</td>\n",
       "      <td>0.787298</td>\n",
       "      <td>0.738836</td>\n",
       "      <td>0.469824</td>\n",
       "      <td>0.380445</td>\n",
       "      <td>0.388171</td>\n",
       "      <td>9.482600</td>\n",
       "      <td>264.484000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-09 17:09:09,575]\u001b[0m Trial 7 finished with value: 1.977275286576051 and parameters: {'learning_rate': 1.7537894576662728e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4}. Best is trial 0 with value: 2.045549773586954.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1255' max='1255' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1255/1255 03:07, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.943501</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>9.563500</td>\n",
       "      <td>262.248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.991900</td>\n",
       "      <td>0.911684</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.169956</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>9.397200</td>\n",
       "      <td>266.887000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.991900</td>\n",
       "      <td>0.935285</td>\n",
       "      <td>0.681021</td>\n",
       "      <td>0.420160</td>\n",
       "      <td>0.251724</td>\n",
       "      <td>0.205919</td>\n",
       "      <td>9.468200</td>\n",
       "      <td>264.886000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.921300</td>\n",
       "      <td>0.906955</td>\n",
       "      <td>0.687002</td>\n",
       "      <td>0.286885</td>\n",
       "      <td>0.267194</td>\n",
       "      <td>0.237417</td>\n",
       "      <td>9.373400</td>\n",
       "      <td>267.564000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.921300</td>\n",
       "      <td>1.067467</td>\n",
       "      <td>0.661483</td>\n",
       "      <td>0.271586</td>\n",
       "      <td>0.321167</td>\n",
       "      <td>0.294119</td>\n",
       "      <td>9.377700</td>\n",
       "      <td>267.443000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-09 17:12:20,945]\u001b[0m Trial 8 finished with value: 1.548355378103917 and parameters: {'learning_rate': 9.614249383324187e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4}. Best is trial 0 with value: 2.045549773586954.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='252' max='502' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [251/502 00:24 < 00:24, 10.35 it/s, Epoch 1.00/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.327528</td>\n",
       "      <td>0.173445</td>\n",
       "      <td>0.043361</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.073904</td>\n",
       "      <td>9.532100</td>\n",
       "      <td>263.112000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-09 17:12:58,714]\u001b[0m Trial 9 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_run = trainer_hyper.hyperparameter_search(n_trials=10, direction=\"maximize\", hp_space= my_hp_space, compute_objective = my_objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausgabe des besten Versuchs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BestRun(run_id='0', objective=2.045549773586954, hyperparameters={'learning_rate': 1.5262149309394706e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend kann ein neuer Trainer erzeugt werden, welcher die ermittelten Hyperparameter des `best_run` nutzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del trainer_hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem der `best_run` ermittelt wurde, kann nun ein neuer `Trainer` erzeugt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer_hyper = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    #Nutzt das gesamte Trainingsset\n",
    "    train_dataset=dataset_preprocessed[\"train\"],\n",
    "    eval_dataset=dataset_preprocessed[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Hyperparamter des `best_run` werden mit folgendem Loop übertragen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, v in best_run.hyperparameters.items():\n",
    "    setattr(trainer_hyper.args, n, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausgabe der `TrainingArguments` zur Kontrolle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(output_dir=task2_transformer_hyperparametersearch, overwrite_output_dir=False, do_train=False, do_eval=None, do_predict=False, evaluation_strategy=EvaluationStrategy.EPOCH, prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=4, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1.5262149309394706e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_steps=0, logging_dir=runs/Mar09_16-56-07_fastai2, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=True, fp16_opt_level=O1, fp16_backend=auto, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=task2_transformer_hyperparametersearch, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model=eval_f1, greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=[], ddp_find_unused_parameters=None, dataloader_pin_memory=True, _n_gpu=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_hyper.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend kann das Modell mit den durch Optuna gefundenen Hyperparametern trainiert werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='7521' max='7521' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7521/7521 12:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.700800</td>\n",
       "      <td>0.659878</td>\n",
       "      <td>0.785486</td>\n",
       "      <td>0.685201</td>\n",
       "      <td>0.526643</td>\n",
       "      <td>0.565863</td>\n",
       "      <td>9.196300</td>\n",
       "      <td>272.719000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.544800</td>\n",
       "      <td>0.846645</td>\n",
       "      <td>0.795853</td>\n",
       "      <td>0.669712</td>\n",
       "      <td>0.567675</td>\n",
       "      <td>0.605350</td>\n",
       "      <td>9.294800</td>\n",
       "      <td>269.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.372400</td>\n",
       "      <td>1.050228</td>\n",
       "      <td>0.796252</td>\n",
       "      <td>0.643264</td>\n",
       "      <td>0.597003</td>\n",
       "      <td>0.616984</td>\n",
       "      <td>9.411200</td>\n",
       "      <td>266.492000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7521, training_loss=0.5487483626524037, metrics={'train_runtime': 734.5044, 'train_samples_per_second': 10.24, 'total_flos': 1283910321043584, 'epoch': 3.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_hyper.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluierung des Modells mit ungesehenen Testdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "executionInfo": {
     "elapsed": 19530,
     "status": "ok",
     "timestamp": 1611012245947,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "38JWB5ZPccRZ",
    "outputId": "cb6b30a3-04a0-4ce8-8958-5ca5ff943efd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='758' max='758' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [758/758 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2841224670410156,\n",
       " 'eval_accurracy': 0.7548663807324315,\n",
       " 'eval_precision': 0.6088060857083276,\n",
       " 'eval_recall': 0.5185129282249112,\n",
       " 'eval_f1': 0.545834327689768,\n",
       " 'eval_runtime': 11.6654,\n",
       " 'eval_samples_per_second': 259.828,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_hyper.evaluate(dataset_preprocessed[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lVJw6pa3KSn"
   },
   "source": [
    "Speichern des Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "15vmcUZaceGA"
   },
   "outputs": [],
   "source": [
    "trainer_hyper.save_model(f'./deepset_finetuned/offensive_language_deepset_{task}_hyperparametersearch_finetune_gem_germeval2019_split_makrof1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 827,
     "status": "ok",
     "timestamp": 1611013034496,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "CEJVATXR22qy",
    "outputId": "955fb5f0-5bf0-479b-d18f-5d0e676be0cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./deepset_finetuned/offensive_language_deepset_task2_hyperparametersearch_finetune_gem_germeval2019_split_makrof1/tokenizer_config.json',\n",
       " './deepset_finetuned/offensive_language_deepset_task2_hyperparametersearch_finetune_gem_germeval2019_split_makrof1/special_tokens_map.json',\n",
       " './deepset_finetuned/offensive_language_deepset_task2_hyperparametersearch_finetune_gem_germeval2019_split_makrof1/vocab.txt',\n",
       " './deepset_finetuned/offensive_language_deepset_task2_hyperparametersearch_finetune_gem_germeval2019_split_makrof1/added_tokens.json')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(f'./deepset_finetuned/offensive_language_deepset_{task}_hyperparametersearch_finetune_gem_germeval2019_split_makrof1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beispielhafte Anwendung des Modells\n",
    "Um ein Transformers Modell einfach anzuwenden, nutzt man die Methode `pipeline`. Diese baut automatisch in Abhängigkeit vom übergebenen Task und Modell eine Pipeline. Die Pipeline kümmert sich um die nötigen Schritte um aus einer Stringeingabe eine Modellvorhersage zu erzeugen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# der Task für SequenceClassification ist immer \"sentiment-analysis\"\n",
    "classifier = pipeline(\"sentiment-analysis\",model=f'./deepset_finetuned/offensive_language_deepset_{task}_hyperparametersearch_finetune_gem_germeval2019_split_makrof1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'INSULT', 'score': 0.991036057472229}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Man bist du ein Assi @BertholdBrecht\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'OTHER', 'score': 0.9984234571456909}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('''“Der Sozialismus ist eine Religion der Lüge. Ihre Glaubenssätze sind:\n",
    "            Neid und Missgunst, Hass und Verachtung, Faulheit und Mittelmäßigkeit, \n",
    "            Raub und Diebstahl.” ― Roland Baader\"''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'ABUSE', 'score': 0.9981496334075928}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('So was unfreundliches kann ja nur von einem Türken kommen @Ügütz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'PROFANITY', 'score': 0.9860075116157532}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('@Robinhood Dieser Scheiss der da gestern passiert ist, geht ja mal gar nicht ')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMOYpBAyOcO1JEAGxdjxBex",
   "collapsed_sections": [],
   "mount_file_id": "1Lv13JaIWvZoRvO4cvXP5hvFi1PQTmptU",
   "name": "text classification finetuning_transformer_task1.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-7.mnightly-2021-02-12-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:mnightly-2021-02-12-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d6f7447273c49bcbe6557770812e45a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15be95196266497ab2fbab5e11853161": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6db3d3a6df294530a9756b3873ff6d7a",
      "max": 13,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dff609ca3a5248cd8de78e1ba12b3dba",
      "value": 13
     }
    },
    "1b376abbf52347cea599ecbd8a200f9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d87d7aaa52c94a7cbc2b0145601ff16a",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8196b689e3df44fe93eb6de3ce2d398a",
      "value": 2
     }
    },
    "1d0b4221fcd5470687de22c0d2adcb95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_15be95196266497ab2fbab5e11853161",
       "IPY_MODEL_4d41e7ef93c646ed88b99644e47247c4"
      ],
      "layout": "IPY_MODEL_65f7cf127c6a44a9a4c5a457670cfa3a"
     }
    },
    "48946d29567b4ca79e74c1519ce4e98b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d41e7ef93c646ed88b99644e47247c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_711f7d49b8aa44b886cf8421cf650877",
      "placeholder": "​",
      "style": "IPY_MODEL_baae8d84bcb24170a7c4ff7f6c7a45bc",
      "value": " 13/13 [00:02&lt;00:00,  5.91ba/s]"
     }
    },
    "63b3a67d23b04628bd266546814febff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65f7cf127c6a44a9a4c5a457670cfa3a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6db3d3a6df294530a9756b3873ff6d7a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "711f7d49b8aa44b886cf8421cf650877": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7477eb3df24a4233b83a8b2a40860597": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e7176033658a4bad8c12d76e86afb0d6",
       "IPY_MODEL_ab5198481b23416c9308d2b1088daf62"
      ],
      "layout": "IPY_MODEL_86ff3ad9403d43af94b11942cb0952f9"
     }
    },
    "8196b689e3df44fe93eb6de3ce2d398a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "86ff3ad9403d43af94b11942cb0952f9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99afef5741a248118be99ba48f82e3d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1b376abbf52347cea599ecbd8a200f9b",
       "IPY_MODEL_a2ce89d47bd944e2936859b9d6880d03"
      ],
      "layout": "IPY_MODEL_0d6f7447273c49bcbe6557770812e45a"
     }
    },
    "a2ce89d47bd944e2936859b9d6880d03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48946d29567b4ca79e74c1519ce4e98b",
      "placeholder": "​",
      "style": "IPY_MODEL_e376402eed794262ac376ba1bae6e551",
      "value": " 2/2 [00:00&lt;00:00,  2.79ba/s]"
     }
    },
    "ab5198481b23416c9308d2b1088daf62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcbdcd3f6b4b4d329831b0da8d3c105f",
      "placeholder": "​",
      "style": "IPY_MODEL_f5dcd7aa0ae2476db993b3ee5de33c0f",
      "value": " 2/2 [00:00&lt;00:00,  4.22ba/s]"
     }
    },
    "baae8d84bcb24170a7c4ff7f6c7a45bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d87d7aaa52c94a7cbc2b0145601ff16a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dff609ca3a5248cd8de78e1ba12b3dba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e376402eed794262ac376ba1bae6e551": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7176033658a4bad8c12d76e86afb0d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63b3a67d23b04628bd266546814febff",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f200ec38e21a4fa0a177c1c09e7f6342",
      "value": 2
     }
    },
    "f200ec38e21a4fa0a177c1c09e7f6342": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f5dcd7aa0ae2476db993b3ee5de33c0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fcbdcd3f6b4b4d329831b0da8d3c105f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
