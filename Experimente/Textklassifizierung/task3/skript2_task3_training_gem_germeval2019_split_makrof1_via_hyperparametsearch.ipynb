{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uPMxhsCGC_28"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "T03dQvvEfKLV"
   },
   "outputs": [],
   "source": [
    "#!pip install seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcT7J9elDafr"
   },
   "source": [
    "# Skript2: Model Finetuning mit Hyperparametersuche f√ºr Text-Klassifizierung mit germaneval2019 Task2 -Subtask3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Notebook beschreibt das Training eines Text-Klassifizierungsmodells f√ºr den Datensatz GermEval 2019 Task2 -Subtask3.\n",
    "Es wird ein BERT - Modell mit der nativen Hugging Face Transformer Bibliothek trainiert. Daf√ºr wird vor dem Training mithilfe automatischer Hyperparametersuche versucht, bessere Trainingsparameter zu finden, um die Modellleistung zu verbessern. Das Training erfolgt nach dem gleichen Split wie es der Shared Task 2019 vorgab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IMjJp0dTDQYd"
   },
   "outputs": [],
   "source": [
    "# Importieren der Hugging Face Datesets Bibliothek\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w1-KB44DGj0Y"
   },
   "outputs": [],
   "source": [
    "# Parameter f√ºr die Scriptsteuerung:\n",
    "# die Task f√ºr die das Modell trainiert werden soll\n",
    "task = \"task3\"\n",
    "# das zu verwendende pretrained Transformer Modell\n",
    "model_checkpoint = \"deepset/gbert-base\"\n",
    "# die Trainingsbatchsize\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCubx_AkH_9c"
   },
   "source": [
    "## Preprocessing des Datasets\n",
    "Zun√§chst m√ºssen die Daten aus dem GermEval2019 Datensatz vorverarbeitet werden. Dazu werden diese in einen `Pandas DataFrames` umgewandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HvPtCFtYMl1c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9wMKF4EWZZo"
   },
   "source": [
    "Als ersten werden mit Hilfe der `read_csv()` Methode die Daten f√ºr das Trainings- und das Valiederungsset zu einem `DataFrame` zusammengef√ºgt. Dabei werden die Werte in den Labelspalten in numerische Kategorienencodings umgewandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 6801,
     "status": "ok",
     "timestamp": 1611008225006,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "_EA1WWnEMr-S",
    "outputId": "5a9b7b63-7cce-45d2-b104-ce0deec446b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task1_label</th>\n",
       "      <th>task2_label</th>\n",
       "      <th>task3_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@spdde kein verl√§√ülicher Verhandlungspartner. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@milenahanm 33 bis 45 habe ich noch gar nicht ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@tagesschau Euere AfD Hetze wirkt. Da k√∂nnt ih...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deutsche Medien, Halbwahrheiten und einseitige...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Ralf_Stegner Oman Ralle..dich mag ja immer no...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>@Alltags_Kotze Dein Feminismus und Genderquats...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>@UdoUlfkotte Hauptsache den Asylanten gehts ge...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>@SteinbachErika Ich finde AFD W√§hler besser al...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>@RKnillmann @lawyerberlin @AfD Aha, der Islam ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>@podilein Mannheim, weltoffen und kunterbunt. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1958 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  task1_label  \\\n",
       "0     @spdde kein verl√§√ülicher Verhandlungspartner. ...            0   \n",
       "1     @milenahanm 33 bis 45 habe ich noch gar nicht ...            0   \n",
       "2     @tagesschau Euere AfD Hetze wirkt. Da k√∂nnt ih...            0   \n",
       "3     Deutsche Medien, Halbwahrheiten und einseitige...            0   \n",
       "4     @Ralf_Stegner Oman Ralle..dich mag ja immer no...            0   \n",
       "...                                                 ...          ...   \n",
       "1953  @Alltags_Kotze Dein Feminismus und Genderquats...            0   \n",
       "1954  @UdoUlfkotte Hauptsache den Asylanten gehts ge...            0   \n",
       "1955  @SteinbachErika Ich finde AFD W√§hler besser al...            0   \n",
       "1956  @RKnillmann @lawyerberlin @AfD Aha, der Islam ...            0   \n",
       "1957  @podilein Mannheim, weltoffen und kunterbunt. ...            0   \n",
       "\n",
       "      task2_label  task3_label  \n",
       "0               1            0  \n",
       "1               2            0  \n",
       "2               0            0  \n",
       "3               0            0  \n",
       "4               1            0  \n",
       "...           ...          ...  \n",
       "1953            0            0  \n",
       "1954            0            1  \n",
       "1955            1            0  \n",
       "1956            0            1  \n",
       "1957            0            0  \n",
       "\n",
       "[1958 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all=pd.read_csv(\"../datasets/germeval2019/train_valid/germeval2019.training_subtask3.txt\",delimiter=\"\\t\", header=None,quoting=3)\n",
    "data_all.columns = [\"text\",\"task1_label\",\"task2_label\",\"task3_label\"]\n",
    "# Umwandlung der Label in die jeweiligen numerischen Encodings\n",
    "data_all.task1_label = data_all.task1_label.astype('category').cat.codes\n",
    "data_all.task2_label = data_all.task2_label.astype('category').cat.codes\n",
    "data_all.task3_label = data_all.task3_label.astype('category').cat.codes\n",
    "data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F√ºr das Testdataset wird ebenfalls ein `DataFrame` erzeugt und die Label encodiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task1_label</th>\n",
       "      <th>task2_label</th>\n",
       "      <th>task3_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F√ºr mich ist der morgige Tag ein Tag der \"Gr√∂√ü...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ndaktuell Ach Gott mehr nicht,was gedenkt man...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@gerdm4863 Das ist einfach so...aber noch lang...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@welt Bla bla bla! L√ºgenpresse verkauft uns ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@OnlineMagazin Das kann doch nur ein Fake sein...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>@Schminkflinte @SawsanChebli Mir doch egal, ob...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>@rspctfl @ThomasMichael71 @Innenwelttramp @erg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>Merkel zerst√∂rt den b√ºrgerlich-konservativen K...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>Feminismus ist der Islamismus der Weiblichkeit.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>@ThomasMichael71 @mountainman1977 @houelle_bec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>930 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  task1_label  \\\n",
       "0    F√ºr mich ist der morgige Tag ein Tag der \"Gr√∂√ü...            0   \n",
       "1    @ndaktuell Ach Gott mehr nicht,was gedenkt man...            0   \n",
       "2    @gerdm4863 Das ist einfach so...aber noch lang...            0   \n",
       "3    @welt Bla bla bla! L√ºgenpresse verkauft uns ma...            0   \n",
       "4    @OnlineMagazin Das kann doch nur ein Fake sein...            0   \n",
       "..                                                 ...          ...   \n",
       "925  @Schminkflinte @SawsanChebli Mir doch egal, ob...            0   \n",
       "926  @rspctfl @ThomasMichael71 @Innenwelttramp @erg...            0   \n",
       "927  Merkel zerst√∂rt den b√ºrgerlich-konservativen K...            0   \n",
       "928    Feminismus ist der Islamismus der Weiblichkeit.            0   \n",
       "929  @ThomasMichael71 @mountainman1977 @houelle_bec...            0   \n",
       "\n",
       "     task2_label  task3_label  \n",
       "0              0            0  \n",
       "1              0            0  \n",
       "2              0            0  \n",
       "3              0            0  \n",
       "4              0            0  \n",
       "..           ...          ...  \n",
       "925            0            0  \n",
       "926            0            0  \n",
       "927            0            0  \n",
       "928            0            0  \n",
       "929            0            1  \n",
       "\n",
       "[930 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"../datasets/germeval2019/test/germeval2019GoldLabelsSubtask3.txt\",delimiter=\"\\t\", header=None, quoting=3)\n",
    "data_test.columns = [\"text\",\"task1_label\",\"task2_label\",\"task3_label\"]\n",
    "data_test.task1_label = data_test.task1_label.astype('category').cat.codes\n",
    "data_test.task2_label = data_test.task2_label.astype('category').cat.codes\n",
    "data_test.task3_label = data_test.task3_label.astype('category').cat.codes\n",
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPgChng8W-2R"
   },
   "source": [
    "Anschlie√üend kann aus den `Pandas DataFrames` ein `Hugging Face Dataset` generiert werden. Hierf√ºr wird zun√§chst ein `Feature` Dictionary erzeugt. Dieses enth√§lt Typisierungen f√ºr die Features des Datasets. So werden die Features `task1_label` und `task2_label` jeweils als `ClassLabel` typisiert und das `text` Feature wird als String-Value deklariert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OasUiOPHRlcX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Erzeugen eines DataSet Objektes mit allen Daten\n",
    "features = datasets.Features({\n",
    "  #'__index_level_0__': datasets.Value(dtype='int32', id=None),\n",
    "  'task3_label': datasets.ClassLabel(num_classes=2, names=['EXPLICIT', 'IMPLICIT'], names_file=None, id=None),\n",
    "  'text': datasets.Value(dtype='string', id=None)\n",
    "})\n",
    "dataset = datasets.Dataset.from_pandas(data_all,features=features)\n",
    "dataset_test = datasets.Dataset.from_pandas(data_test,features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beispielausgabe der Dataset Objekte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['task3_label', 'text'],\n",
       "     num_rows: 930\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['task3_label', 'text'],\n",
       "     num_rows: 1958\n",
       " }))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-tOmELjZNGD"
   },
   "source": [
    "#### Split des Datasets\n",
    "Mithilfe der der Dataset Objekte wird anschlie√üend der Trainings- und Validierungssplit durchgef√ºhrt. Die gew√§hlte gr√∂√üe des Validierungsset betr√§gt 20% des Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EiGTIJWUTnlI"
   },
   "outputs": [],
   "source": [
    "# Aufsplitten des Trainingssets in 80/20 (Training/Validation)Split\n",
    "dataset_train_valid = dataset.train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `train_test_split()` Methode gibt ein `DatasetDict` Objekt zur√ºck. Dies ist ein Dictionary mit einem Trainings- und einem Testdataset. Das Testdataset stellt in diesem Fall das Validierungsdataset dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['task3_label', 'text'],\n",
       "        num_rows: 1566\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['task3_label', 'text'],\n",
       "        num_rows: 392\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein gemeinsames Dataset Objekt zu erhalten, werden die Datasets anschlie√üend zusammengef√ºgt und entsprechend des Splits benannt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Jjr8Dp7Fadpp"
   },
   "outputs": [],
   "source": [
    "# Zusammenf√ºgen aller DataSet-Objekte zu einem gemeinsamen DataSet mit benannten Splits\n",
    "dataset_train_valid_test = datasets.DatasetDict({\"train\": dataset_train_valid[\"train\"],\n",
    "                                                 \"valid\": dataset_train_valid[\"test\"],\n",
    "                                                 \"test\": dataset_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufbau des gesamten Dataset Dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7293,
     "status": "ok",
     "timestamp": 1611008225519,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "_8UgCr4ERdSl",
    "outputId": "f7fba697-a7c5-4f5d-c690-609b9b80928a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['task3_label', 'text'],\n",
       "        num_rows: 1566\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['task3_label', 'text'],\n",
       "        num_rows: 392\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['task3_label', 'text'],\n",
       "        num_rows: 930\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_valid_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTA7nlywIniv"
   },
   "source": [
    "Funktion f√ºr die Ausgabe von Beispieldaten aus dem Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uEnpzJT7Iegv"
   },
   "outputs": [],
   "source": [
    "# Quelle in Anlehnung an: https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/text_classification.ipynb#scrollTo=X6HrpprwIrIz\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10,seed=None):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    random.seed(seed)\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            random.seed(seed)\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausgabe von Beispieldaten aus dem Trainingsdataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 8263,
     "status": "ok",
     "timestamp": 1611008226504,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "vRus2k0ZIqyJ",
    "outputId": "ff95e91c-38a2-4a6c-981d-9a3dd410b55d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task3_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXPLICIT</td>\n",
       "      <td>@MDRINFO @KontraKulturell |LBR| ab nach Hause mit dem Pack.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXPLICIT</td>\n",
       "      <td>@Heinrich_Krug @krippmarie Sorry aber das ist schon gruselig wie Merkel aussieht....irgendwie passt die optisch besser zu den Afghanen oder Syrern üò°üò°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXPLICIT</td>\n",
       "      <td>Warum hat wohl der Terrorf√ºrst Yassir #Arafat das Wort ¬ª#Pal√§stinenser¬´ f√ºr die #Araber in der #Levante benutzt? Dieses Volk gab es vorher nicht, aber man bediente sich aus dem #Antisemitismus der #R√∂mer, die uns #Juden dem√ºtigten &amp;amp; Eretz #Israel in #Pal√§stina¬´ unbenannten.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMPLICIT</td>\n",
       "      <td>@BonkeKolja Was h√§tte A. H. mit solche skupellosen T√§tern gemacht? Sicher das Richtige!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXPLICIT</td>\n",
       "      <td>@DoraBromberger Hoffentlich bekommt die dumme, gewaltbereite Antifantenbrut richtig auf die Fresse! ‚òªüëπü§ò |LBR| Respekt f√ºr friedliche Demonstranten! üëç üëç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EXPLICIT</td>\n",
       "      <td>@SchauHin2 |LBR| Hoffentlich sind die Nationalisten dann die Sieger nicht die Asylantenbesch√ºtzer und Asyalantenabschaum?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EXPLICIT</td>\n",
       "      <td>@stefanolix @teite99 Nutzbringende Migration bedingt Abwehr der nutzlosen Migration.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXPLICIT</td>\n",
       "      <td>@sentenza66 DIESES GESAMTE GESOCKSE MIT IHREM CLAN MUSS INNERHALB EINES TAGES RAUS AUS DEUTSCHLAND!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXPLICIT</td>\n",
       "      <td>@tagesschau Warum schreibt ihr Merkel Vasallen nicht mal die Wahrheit √ºber Merkels Verbrech? Ach ja, dann seid ihr ja Arbeitslos!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXPLICIT</td>\n",
       "      <td>@ArasBacho @dushanwegner Eine dumme Labertasche dieser @ArasBacho ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset_train_valid_test[\"train\"],seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKOyNmu29mJh"
   },
   "source": [
    "# Preprocessing der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9n5Si_z-GPZ"
   },
   "source": [
    "Beschaffen des zugeh√∂rigen Tokenizers zum ausgew√§hlten Modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hdtek_WJ21iW"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Tokenizer kann direkt genutzt werden, um eine Inputsequenz zu tokenisieren. Dabei erh√§lt man ein Dictionary mit Mappings zu den input_ids, token_type_ids und eine attention_mask. Die input_id ist die Identifikation des jeweiligen Tokens im Vokabluar des Modells. Token_type_ids markieren Tokens in Seq2Seq Tasks und geben dem Modell Informationen dar√ºber, zu welchem Teil einer zweiteiligen Eingabesequenz ein Token geh√∂rt. Die attention_mask teilt dem Modell mit, f√ºr welche Token die Attention berechnet werden soll. Ist eine Eingabesequenz z. B. sehr kurz im Gegensatz zu den anderen, dann wird diese per Padding auf die gleiche L√§nge gebracht. Die attention_mask verhindert anschlie√üend, dass die Attention f√ºr diese Padding Token berechnet wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12322,
     "status": "ok",
     "timestamp": 1611008230579,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "eX3dokKC-EBJ",
    "outputId": "adf21783-9a9a-4cc2-e5b1-6fa9b1be7691"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [102, 479, 215, 3392, 827, 12822, 313, 3750, 2809, 8550, 205, 11473, 11545, 7232, 276, 190, 8448, 106, 128, 21429, 205, 3915, 566, 2302, 1523, 28283, 105, 818, 276, 128, 2233, 5099, 205, 21713, 11044, 566, 103], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Es ist nat√ºrlich viel einfacher auch weiterhin jeden Widerstand zu skandalisieren als den Konzernen die Stirn zu bieten. Ist einfach gem√ºtlicher, als die eigenen Fehler zu reflektieren.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Daten der Datasets vorzuverarbeiten wird die folgende Methode definiert\\\n",
    "In der Methode werden zun√§chst die Werte des `text` Features mit dem Tokenizer des Modells tokeniesiert und anschlie√üend ein Label Attribut mit dem Wert der aktuellen Task eingef√ºgt. Die Methode gibt Ausgabe des Tokenizers anschlie√üend zur√ºck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2GnFhohw-d-1"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "  tokenized_inputs = tokenizer(data['text'], truncation=True)\n",
    "  label = data[\"task3_label\"]\n",
    "  tokenized_inputs[\"label\"] = label\n",
    "  return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6QhEXZt_41k"
   },
   "source": [
    "Die Funktion kann beliebig viele Datens√§tze verarbeiten. Werden mehrere √ºbergeben dann gibt der Tokenizer eine Liste zur√ºck:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12311,
     "status": "ok",
     "timestamp": 1611008230580,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "ivcqbxsL_ZBP",
    "outputId": "6538c988-af1a-455a-ac6f-0e4915218f07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[102, 17329, 9036, 30901, 1926, 2420, 30887, 17329, 2942, 13589, 30893, 2675, 11159, 105, 764, 778, 847, 292, 5353, 237, 566, 566, 566, 566, 103]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'label': [0]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_data(dataset_train_valid_test[\"train\"][:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0FGhYm_AR9U"
   },
   "source": [
    "Anwendung der `preprocess_data` Funktion auf alle Teildatens√§tze im DataSet-Objekt `dataset_train_valid_test` mithilfe von `map`\n",
    " - `batched=True` beschleunigt die Verarbeitung des FastTokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167,
     "referenced_widgets": [
      "1d0b4221fcd5470687de22c0d2adcb95",
      "65f7cf127c6a44a9a4c5a457670cfa3a",
      "15be95196266497ab2fbab5e11853161",
      "4d41e7ef93c646ed88b99644e47247c4",
      "dff609ca3a5248cd8de78e1ba12b3dba",
      "6db3d3a6df294530a9756b3873ff6d7a",
      "baae8d84bcb24170a7c4ff7f6c7a45bc",
      "711f7d49b8aa44b886cf8421cf650877",
      "99afef5741a248118be99ba48f82e3d9",
      "0d6f7447273c49bcbe6557770812e45a",
      "1b376abbf52347cea599ecbd8a200f9b",
      "a2ce89d47bd944e2936859b9d6880d03",
      "8196b689e3df44fe93eb6de3ce2d398a",
      "d87d7aaa52c94a7cbc2b0145601ff16a",
      "e376402eed794262ac376ba1bae6e551",
      "48946d29567b4ca79e74c1519ce4e98b",
      "7477eb3df24a4233b83a8b2a40860597",
      "86ff3ad9403d43af94b11942cb0952f9",
      "e7176033658a4bad8c12d76e86afb0d6",
      "ab5198481b23416c9308d2b1088daf62",
      "f200ec38e21a4fa0a177c1c09e7f6342",
      "63b3a67d23b04628bd266546814febff",
      "f5dcd7aa0ae2476db993b3ee5de33c0f",
      "fcbdcd3f6b4b4d329831b0da8d3c105f"
     ]
    },
    "executionInfo": {
     "elapsed": 14410,
     "status": "ok",
     "timestamp": 1611008232685,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "twrsVzjj_mR8",
    "outputId": "4876bb83-6d0f-4794-d152-9c88cfee069a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27cfc50c4b841079dfefad9238a24b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4ead63b7954469a6582fe590ce6fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697495f747b74810a14051957a1bb97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_preprocessed = dataset_train_valid_test.map(preprocess_data,batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gb_TD4XlBWVb"
   },
   "source": [
    "Durch das Preprocessing werden die Ausgaben des Tokenizers als Features des DataSets erg√§nzt.\\\n",
    "In der folgenden Ausgaben sieht man, dass nun die attention_mask, die input_ids, die label und die token_type_ids als Features erg√§nzt wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14404,
     "status": "ok",
     "timestamp": 1611008232686,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "06uMbiXMA6cy",
    "outputId": "b7331279-1f55-4304-b6ae-ec8e72fb2fec",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'label', 'task3_label', 'text', 'token_type_ids'],\n",
       "    num_rows: 1566\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_preprocessed[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>label</th>\n",
       "      <th>task3_label</th>\n",
       "      <th>text</th>\n",
       "      <th>token_type_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[102, 17329, 25704, 30420, 30931, 22646, 17329, 11653, 16966, 630, 18406, 183, 14822, 18406, 404, 333, 3873, 212, 249, 13910, 566, 103]</td>\n",
       "      <td>0</td>\n",
       "      <td>EXPLICIT</td>\n",
       "      <td>@MDRINFO @KontraKulturell |LBR| ab nach Hause mit dem Pack.</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[102, 17329, 4669, 2032, 20611, 30894, 17329, 15442, 2355, 1303, 110, 9147, 2690, 494, 199, 215, 778, 872, 22664, 214, 335, 6488, 18138, 566, 566, 566, 566, 11896, 10576, 128, 29872, 1903, 205, 190, 14016, 106, 394, 7791, 310, 101, 103]</td>\n",
       "      <td>0</td>\n",
       "      <td>EXPLICIT</td>\n",
       "      <td>@Heinrich_Krug @krippmarie Sorry aber das ist schon gruselig wie Merkel aussieht....irgendwie passt die optisch besser zu den Afghanen oder Syrern üò°üò°</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset_preprocessed[\"train\"],seed=42,num_examples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzkAGoLuCEOT"
   },
   "source": [
    "# Finetuning des Modells mit Hyperparametersearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kx9YcmiEGs4V"
   },
   "source": [
    "F√ºr die Konstruktion des Modells wird ein Label-ID Mapping erzeugt. Dieses Mapping wird anschlie√üend in der Configuration des Modells hinterlegt. Es erm√∂glicht dem Modell die vorhergesagten Label als Texte auszugeben anstatt ihrer numerischen Kodierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AC8I1QPTFIv9"
   },
   "outputs": [],
   "source": [
    "id2label = {\"0\":\"EXPLICIT\", \"1\":\"IMPLICIT\"}\n",
    "label2id = {\"EXPLICIT\": \"0\", \"IMPLICIT\":\"1\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqUjcxMAGyCe"
   },
   "source": [
    "Erzeugen und Konfiguration des Modells mit Label-ID Mapping:\n",
    " - `AutoModelForSequenceClassification.from_pretrained` l√§dt automatisch das entsprechende Modell herunter und initialisiert einen Klassifizierungskopf am Ende des Modells.\n",
    " - Die auftretenden Warnungen geben nur Auskunft dar√ºber, dass der Kopf des Modells ausgetauscht wurde und demzufolge keine trainierten Weights hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Annahme, dass bessere gew√§hlte Hyperparameter leistungsst√§rkeren Modellen f√ºhren, wird im folgenden Abschnitt mithilfe von automatischer Hyperparametersuche versucht, die Modellperformance weiter zu steigern. \\\n",
    "Hierf√ºr wird das Modul optuna genutzt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es muss eine Funktion erstellt werden, die das zu trainierende Modell nach jedem Versuch wieder initalisiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "num_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisiert ein neues Modell auf Basis des gew√§hlten Modell Checkpoints\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuRkOYLmJKc8"
   },
   "source": [
    "#### Vorbereitung f√ºr die Erzeugung des `Trainers`:\n",
    "- Es m√ºssen zun√§chst die `TrainingArguments` konfiguriert werden, dabei handelt es sich um die Hyperparameter des Trainings:\n",
    " - Dazu z√§hlen z.B. die Anzahl der Epoch, die Learning Rate, die Batchsize und der weight_decay\n",
    " - `load_best_model_at_end` und `metric_for_best_model` sorgen daf√ºr, dass am Ende des Trainings das Model mit der h√∂chsten `F1_Score` geladen wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "gyKgE9MXCyUM"
   },
   "outputs": [],
   "source": [
    "metric_name = 'eval_f1'\n",
    "\n",
    "args = TrainingArguments( \n",
    "    output_dir= f\"{task}_transformer_hyperparametersearch\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    # empfohlener Standardwert f√ºr das Finetuning\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    # empfohlener Standardwert f√ºr das Finetuning\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    # fp16 transformiert das Modell nach float16 um Memory zu sparen und die Trainingszeit zu verringern\n",
    "    fp16=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLTFfL73KtsO"
   },
   "source": [
    "Damit das Modell w√§hrend des Trainings die gew√ºnschten Metriken berechnen kann, muss eine Funktion definiert werden die diese Metriken berechnet. Das √ºbernimmt die `compute_metric` Funktion:\n",
    "- Die Datasets Bibliothek erm√∂glicht es, Funktionen zur Berechnung von Metriken herunterzuladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "rm6IRaplamcX"
   },
   "outputs": [],
   "source": [
    "metric_acc = datasets.load_metric(\"accuracy\")\n",
    "metric_f1 = datasets.load_metric(\"f1\")\n",
    "metric_prec = datasets.load_metric(\"precision\")\n",
    "metric_rec = datasets.load_metric(\"recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Metriken werden nun wie folgt in der `compute_metrics` Funktion berechnet. Die Funktion liefert anschlie√üend ein Dictionary mit den vier Metriken `accuracy, precision, recall, f1` zur√ºck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "-dwIvncrKzGx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(p):\n",
    "  predictions, labels = p\n",
    "  predictions = np.argmax(predictions, axis=1)\n",
    "  accurracy = metric_acc.compute(predictions=predictions, references=labels)\n",
    "  f1 = metric_f1.compute(predictions=predictions, references=labels, average=\"macro\" )\n",
    "  prec = metric_prec.compute(predictions=predictions, references=labels,average=\"macro\")\n",
    "  recall = metric_rec.compute(predictions=predictions, references=labels,average=\"macro\")\n",
    " \n",
    "  return {\n",
    "      \"accurracy\" : accurracy[\"accuracy\"],\n",
    "      \"precision\" : prec[\"precision\"],\n",
    "      \"recall\": recall[\"recall\"],\n",
    "      \"f1\": f1[\"f1\"]\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T99e_CdMMl5G"
   },
   "source": [
    "Anschlie√üend muss ein Trainer initialisiert werden, welcher f√ºr die Hyperparametersuche genutzt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "j923iZq8LsZs",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer_hyper = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=dataset_preprocessed[\"train\"].shard(index=1, num_shards=10),\n",
    "    eval_dataset=dataset_preprocessed[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Festlegen der Hyperparameter die getestet werden sollen:\n",
    "- In diesem Beispiel werden Werte f√ºr die Learning Rate und die Anzahl der Epochs ermittelt. \n",
    "- Die Batchsize wurde auf 4 gesetzt um Out of Memoryprobleme zu vermeiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-2, log=True),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 1, 5),\n",
    "        #Festlegen er maximalen Batchsize um Cuda out of Memory zu vermeiden\n",
    "        #\"per_device_train_batch_size\": trial.suggest_int(\"per_device_train_batch_size\", 4,4),\n",
    "        #\"per_device_eval_batch_size\": trial.suggest_int(\"per_device_eval_batch_size\",4,4),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [4, 8, 16, 32, 64]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F√ºr die Hyperparametersuche muss festgelegt werden, wie ein Durchlauf bewertetet werden soll.\n",
    "Hierf√ºr werden mit der folgenden Funktion alle vom Modell berechneten Metriken aufsummiert. Die Summe ist der Score f√ºr die Epoch des jeweiligen Versuchs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def my_objective(metrics) -> float:\n",
    "    metrics = copy.deepcopy(metrics)\n",
    "    loss = metrics.pop(\"eval_loss\", None)\n",
    "    _ = metrics.pop(\"epoch\", None)\n",
    "    _ = metrics.pop(\"eval_runtime\",None)\n",
    "    _ = metrics.pop(\"eval_samples_per_second\",None)\n",
    "    return loss if len(metrics) == 0 else sum(metrics.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starten der Hyperparametersuche:\n",
    "- es werden 10 Versuche durchgef√ºhrt\n",
    "- `direction=\"maximize\"` sorgt daf√ºr, dass das beste Modell anhand der Maximalen Punktzahl der Evaluationsmetriken ausgew√§hlt wird\n",
    "- die Methode returned als Ergebnis die verwendeten Hyperparameter des besten Versuchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-10 10:31:24,212]\u001b[0m A new study created in memory with name: no-name-dcf8cb3e-4041-4a79-a83d-eea016a447b9\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.427662</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.528900</td>\n",
       "      <td>256.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.411555</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.554900</td>\n",
       "      <td>252.101000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-10 10:31:57,839]\u001b[0m Trial 0 finished with value: 2.2563810455689124 and parameters: {'learning_rate': 0.005184459747092712, 'num_train_epochs': 2, 'per_device_train_batch_size': 8}. Best is trial 0 with value: 2.2563810455689124.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 01:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.482403</td>\n",
       "      <td>0.150510</td>\n",
       "      <td>0.569767</td>\n",
       "      <td>0.507396</td>\n",
       "      <td>0.137026</td>\n",
       "      <td>1.535700</td>\n",
       "      <td>255.266000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.405821</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.595400</td>\n",
       "      <td>245.704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.407504</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.669600</td>\n",
       "      <td>234.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.396716</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.648400</td>\n",
       "      <td>237.809000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.380799</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.534100</td>\n",
       "      <td>255.525000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-10 10:33:03,907]\u001b[0m Trial 1 finished with value: 2.2563810455689124 and parameters: {'learning_rate': 0.00023119263697908148, 'num_train_epochs': 5, 'per_device_train_batch_size': 64}. Best is trial 0 with value: 2.2563810455689124.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.394171</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.472300</td>\n",
       "      <td>266.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.385366</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.560300</td>\n",
       "      <td>251.239000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.423050</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.577300</td>\n",
       "      <td>248.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.391364</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.555600</td>\n",
       "      <td>251.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.381297</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>0.538900</td>\n",
       "      <td>0.540625</td>\n",
       "      <td>1.527300</td>\n",
       "      <td>256.667000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-10 10:33:55,860]\u001b[0m Trial 2 finished with value: 2.627633618896888 and parameters: {'learning_rate': 5.15697224769608e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 32}. Best is trial 2 with value: 2.627633618896888.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:21, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.839709</td>\n",
       "      <td>0.137755</td>\n",
       "      <td>0.068878</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.121076</td>\n",
       "      <td>1.454100</td>\n",
       "      <td>269.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.495086</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.569800</td>\n",
       "      <td>249.712000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-10 10:34:21,577]\u001b[0m Trial 3 finished with value: 2.2563810455689124 and parameters: {'learning_rate': 0.0026901621486008238, 'num_train_epochs': 2, 'per_device_train_batch_size': 16}. Best is trial 2 with value: 2.627633618896888.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:21, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.496206</td>\n",
       "      <td>0.829082</td>\n",
       "      <td>0.428760</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.453278</td>\n",
       "      <td>1.495100</td>\n",
       "      <td>262.186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.464523</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.430052</td>\n",
       "      <td>0.491124</td>\n",
       "      <td>0.458564</td>\n",
       "      <td>1.550200</td>\n",
       "      <td>252.874000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-10 10:34:47,796]\u001b[0m Trial 4 finished with value: 2.2266783852483383 and parameters: {'learning_rate': 2.0526695468504564e-06, 'num_train_epochs': 2, 'per_device_train_batch_size': 16}. Best is trial 2 with value: 2.627633618896888.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:23, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.419328</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.552700</td>\n",
       "      <td>252.467000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.645843</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.478200</td>\n",
       "      <td>265.184000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-10 10:35:15,466]\u001b[0m Trial 5 finished with value: 2.2563810455689124 and parameters: {'learning_rate': 0.0012090120198766589, 'num_train_epochs': 2, 'per_device_train_batch_size': 4}. Best is trial 2 with value: 2.627633618896888.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='161' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 00:33, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.469801</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.570200</td>\n",
       "      <td>249.647000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.670254</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.492000</td>\n",
       "      <td>262.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.603062</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.526000</td>\n",
       "      <td>256.879000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.700188</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.549600</td>\n",
       "      <td>252.973000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-10 10:35:55,184]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.408859</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.526400</td>\n",
       "      <td>256.808000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-10 10:36:10,376]\u001b[0m Trial 7 finished with value: 2.2563810455689124 and parameters: {'learning_rate': 2.7129478498085397e-06, 'num_train_epochs': 1, 'per_device_train_batch_size': 4}. Best is trial 2 with value: 2.627633618896888.\u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='6' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6/10 00:00 < 00:00, 9.35 it/s, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.876797</td>\n",
       "      <td>0.137755</td>\n",
       "      <td>0.068878</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.121076</td>\n",
       "      <td>1.481600</td>\n",
       "      <td>264.574000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-10 10:36:16,300]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.534154</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463014</td>\n",
       "      <td>1.467600</td>\n",
       "      <td>267.101000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-03-10 10:36:28,454]\u001b[0m Trial 9 finished with value: 2.2563810455689124 and parameters: {'learning_rate': 0.002519008229003671, 'num_train_epochs': 1, 'per_device_train_batch_size': 64}. Best is trial 2 with value: 2.627633618896888.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_run = trainer_hyper.hyperparameter_search(n_trials=10, direction=\"maximize\", hp_space= my_hp_space, compute_objective = my_objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausgabe des besten Versuchs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BestRun(run_id='2', objective=2.627633618896888, hyperparameters={'learning_rate': 5.15697224769608e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 32})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschlie√üend kann ein neuer Trainer erzeugt werden, welcher die ermittelten Hyperparameter des `best_run` nutzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del trainer_hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem der `best_run` ermittelt wurde, kann nun ein neuer `Trainer` erzeugt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer_hyper = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    #Nutzt das gesamte Trainingsset\n",
    "    train_dataset=dataset_preprocessed[\"train\"],\n",
    "    eval_dataset=dataset_preprocessed[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Hyperparamter des `best_run` werden mit folgendem Loop √ºbertragen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, v in best_run.hyperparameters.items():\n",
    "    setattr(trainer_hyper.args, n, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausgabe der `TrainingArguments` zur Kontrolle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(output_dir=task3_transformer_hyperparametersearch, overwrite_output_dir=False, do_train=False, do_eval=None, do_predict=False, evaluation_strategy=EvaluationStrategy.EPOCH, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=4, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5.15697224769608e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=5, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_steps=0, logging_dir=runs/Mar10_10-31-14_fastai3, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=True, fp16_opt_level=O1, fp16_backend=auto, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=task3_transformer_hyperparametersearch, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model=eval_f1, greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=[], ddp_find_unused_parameters=None, dataloader_pin_memory=True, _n_gpu=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_hyper.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschlie√üend kann das Modell mit den durch Optuna gefundenen Hyperparametern trainiert werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 01:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accurracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.288670</td>\n",
       "      <td>0.882653</td>\n",
       "      <td>0.835979</td>\n",
       "      <td>0.597414</td>\n",
       "      <td>0.629642</td>\n",
       "      <td>1.495600</td>\n",
       "      <td>262.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.319227</td>\n",
       "      <td>0.844388</td>\n",
       "      <td>0.693112</td>\n",
       "      <td>0.746384</td>\n",
       "      <td>0.713419</td>\n",
       "      <td>1.449900</td>\n",
       "      <td>270.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.443544</td>\n",
       "      <td>0.885204</td>\n",
       "      <td>0.767149</td>\n",
       "      <td>0.692253</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>1.593500</td>\n",
       "      <td>246.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.537643</td>\n",
       "      <td>0.882653</td>\n",
       "      <td>0.765278</td>\n",
       "      <td>0.667434</td>\n",
       "      <td>0.699607</td>\n",
       "      <td>1.461300</td>\n",
       "      <td>268.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.576228</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.782292</td>\n",
       "      <td>0.678172</td>\n",
       "      <td>0.712667</td>\n",
       "      <td>1.487100</td>\n",
       "      <td>263.593000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=245, training_loss=0.1504965334522481, metrics={'train_runtime': 78.8792, 'train_samples_per_second': 3.106, 'total_flos': 495417567043728, 'epoch': 5.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_hyper.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluierung des Modells mit ungesehenen Testdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "executionInfo": {
     "elapsed": 19530,
     "status": "ok",
     "timestamp": 1611012245947,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "38JWB5ZPccRZ",
    "outputId": "cb6b30a3-04a0-4ce8-8958-5ca5ff943efd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='233' max='233' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [233/233 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5382338762283325,\n",
       " 'eval_accurracy': 0.8612903225806452,\n",
       " 'eval_precision': 0.7142946366723066,\n",
       " 'eval_recall': 0.6769200480012001,\n",
       " 'eval_f1': 0.6925257381868322,\n",
       " 'eval_runtime': 3.5035,\n",
       " 'eval_samples_per_second': 265.449,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_hyper.evaluate(dataset_preprocessed[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lVJw6pa3KSn"
   },
   "source": [
    "Speichern des Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "15vmcUZaceGA"
   },
   "outputs": [],
   "source": [
    "trainer_hyper.save_model(f'./deepset_finetuned/offensive_language_deepset_{task}_hyperparametersearch_finetune_gem_germeval2019_split_makrof1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 827,
     "status": "ok",
     "timestamp": 1611013034496,
     "user": {
      "displayName": "C B",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8FqdPw5zPMAzFxmBlKBbPOloHNXSr9nSMmtqPKw=s64",
      "userId": "02705570072099363487"
     },
     "user_tz": -60
    },
    "id": "CEJVATXR22qy",
    "outputId": "955fb5f0-5bf0-479b-d18f-5d0e676be0cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./deepset_finetuned/offensive_language_deepset_task3_hyperparametersearch_finetune_gem_germeval2019_split_makrof1/tokenizer_config.json',\n",
       " './deepset_finetuned/offensive_language_deepset_task3_hyperparametersearch_finetune_gem_germeval2019_split_makrof1/special_tokens_map.json',\n",
       " './deepset_finetuned/offensive_language_deepset_task3_hyperparametersearch_finetune_gem_germeval2019_split_makrof1/vocab.txt',\n",
       " './deepset_finetuned/offensive_language_deepset_task3_hyperparametersearch_finetune_gem_germeval2019_split_makrof1/added_tokens.json')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(f'./deepset_finetuned/offensive_language_deepset_{task}_hyperparametersearch_finetune_gem_germeval2019_split_makrof1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beispielhafte Anwendung des Modells\n",
    "Um ein Transformers Modell einfach anzuwenden, nutzt man die Methode `pipeline`. Diese baut automatisch in Abh√§ngigkeit vom √ºbergebenen Task und Modell eine Pipeline. Die Pipeline k√ºmmert sich um die n√∂tigen Schritte um aus einer Stringeingabe eine Modellvorhersage zu erzeugen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# der Task f√ºr SequenceClassification ist immer \"sentiment-analysis\"\n",
    "classifier = pipeline(\"sentiment-analysis\",model=f'./deepset_finetuned/offensive_language_deepset_{task}_hyperparametersearch_finetune_gem_germeval2019_split_makrof1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'EXPLICIT', 'score': 0.9987521171569824}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Unglaublich wie beschissen du heute gespielt hast @ThomasM√ºller\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'IMPLICIT', 'score': 0.6701172590255737}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('Das klingt so als w√§re da jemand als Baby vom Wickeltisch gefallen @UriGe')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMOYpBAyOcO1JEAGxdjxBex",
   "collapsed_sections": [],
   "mount_file_id": "1Lv13JaIWvZoRvO4cvXP5hvFi1PQTmptU",
   "name": "text classification finetuning_transformer_task1.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d6f7447273c49bcbe6557770812e45a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15be95196266497ab2fbab5e11853161": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6db3d3a6df294530a9756b3873ff6d7a",
      "max": 13,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dff609ca3a5248cd8de78e1ba12b3dba",
      "value": 13
     }
    },
    "1b376abbf52347cea599ecbd8a200f9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d87d7aaa52c94a7cbc2b0145601ff16a",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8196b689e3df44fe93eb6de3ce2d398a",
      "value": 2
     }
    },
    "1d0b4221fcd5470687de22c0d2adcb95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_15be95196266497ab2fbab5e11853161",
       "IPY_MODEL_4d41e7ef93c646ed88b99644e47247c4"
      ],
      "layout": "IPY_MODEL_65f7cf127c6a44a9a4c5a457670cfa3a"
     }
    },
    "48946d29567b4ca79e74c1519ce4e98b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d41e7ef93c646ed88b99644e47247c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_711f7d49b8aa44b886cf8421cf650877",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_baae8d84bcb24170a7c4ff7f6c7a45bc",
      "value": " 13/13 [00:02&lt;00:00,  5.91ba/s]"
     }
    },
    "63b3a67d23b04628bd266546814febff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65f7cf127c6a44a9a4c5a457670cfa3a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6db3d3a6df294530a9756b3873ff6d7a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "711f7d49b8aa44b886cf8421cf650877": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7477eb3df24a4233b83a8b2a40860597": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e7176033658a4bad8c12d76e86afb0d6",
       "IPY_MODEL_ab5198481b23416c9308d2b1088daf62"
      ],
      "layout": "IPY_MODEL_86ff3ad9403d43af94b11942cb0952f9"
     }
    },
    "8196b689e3df44fe93eb6de3ce2d398a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "86ff3ad9403d43af94b11942cb0952f9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99afef5741a248118be99ba48f82e3d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1b376abbf52347cea599ecbd8a200f9b",
       "IPY_MODEL_a2ce89d47bd944e2936859b9d6880d03"
      ],
      "layout": "IPY_MODEL_0d6f7447273c49bcbe6557770812e45a"
     }
    },
    "a2ce89d47bd944e2936859b9d6880d03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48946d29567b4ca79e74c1519ce4e98b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e376402eed794262ac376ba1bae6e551",
      "value": " 2/2 [00:00&lt;00:00,  2.79ba/s]"
     }
    },
    "ab5198481b23416c9308d2b1088daf62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcbdcd3f6b4b4d329831b0da8d3c105f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f5dcd7aa0ae2476db993b3ee5de33c0f",
      "value": " 2/2 [00:00&lt;00:00,  4.22ba/s]"
     }
    },
    "baae8d84bcb24170a7c4ff7f6c7a45bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d87d7aaa52c94a7cbc2b0145601ff16a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dff609ca3a5248cd8de78e1ba12b3dba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e376402eed794262ac376ba1bae6e551": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7176033658a4bad8c12d76e86afb0d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63b3a67d23b04628bd266546814febff",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f200ec38e21a4fa0a177c1c09e7f6342",
      "value": 2
     }
    },
    "f200ec38e21a4fa0a177c1c09e7f6342": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f5dcd7aa0ae2476db993b3ee5de33c0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fcbdcd3f6b4b4d329831b0da8d3c105f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
